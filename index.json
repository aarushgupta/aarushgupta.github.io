[{"authors":null,"categories":null,"content":"I am a research engineer at Rephrase.ai, where I work on developing tech which generates videos from just text. I recently graduated from IIT Roorkee with a bachelor\u0026rsquo;s degree in Computer Science and Engineering. I am broadly in Deep Learning, with applications in Computer Vision and Natural Language Processing.\nDuring my undergrad days, I was fortunate to work with Prof. Hanspeter Pfister and Dr. Donglai Wei at Harvard University, Prof. Venkatesh Babu’s group at Indian Institute of Science, and Prof. Marco Pedersoli and Prof. Jose Dolz at École de Technologie Supérieure. I was also the Vice-Chair of ACM IIT Roorkee Student Chapter, and co-led a Deep Learning reading group named the Vision and Language Group\nApart from AI, I am enthusiastic about financial markets, guitar, food, and movies.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://aarushgupta.github.io/author/aarush-gupta/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/aarush-gupta/","section":"authors","summary":"I am a research engineer at Rephrase.ai, where I work on developing tech which generates videos from just text. I recently graduated from IIT Roorkee with a bachelor\u0026rsquo;s degree in Computer Science and Engineering.","tags":null,"title":"Aarush Gupta","type":"authors"},{"authors":["Donglai Wei","Zudi Lin","Daniel Franco-Barranco","Nils Wendt","Xingyu Liu","Wenjie Yin","Xin Huang","Aarush Gupta","Won-Dong Jang","Xueying Wang","Ignacio Arganda-Carreras","Jeff W. Lichtman","Hanspeter Pfister"],"categories":null,"content":"","date":1591036200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1591036200,"objectID":"a26a4c44ab90a4ca5a380aa3e12844cf","permalink":"https://aarushgupta.github.io/publication/mito/","publishdate":"2020-06-02T00:00:00+05:30","relpermalink":"/publication/mito/","section":"publication","summary":"Electron microscopy (EM) allows the identification of intracellular organelles such as mitochondria, providing insights for clinical and scientific studies. However, public mitochondria segmentation datasets only contain hundreds of instances with simple shapes. It is unclear if existing methods achieving human-level accuracy on these small datasets are robust in practice. To this end, we introduce the MitoEM dataset, a 3D mitochondria instance segmentation dataset with two (30   μ m)  3  volumes from human and rat cortices respectively, 3,600  ×  larger than previous benchmarks. With around 40K instances, we find a great diversity of mitochondria in terms of shape and density. For evaluation, we tailor the implementation of the average precision (AP) metric for 3D data with a 45  ×  speedup. On MitoEM, we find existing instance segmentation methods often fail to correctly segment mitochondria with complex shapes or close contacts with other instances. Thus, our MitoEM dataset poses new challenges to the field. We release our code and data: https://donglaiw.github.io/page/mitoEM/index.html","tags":[],"title":"MitoEM Dataset: Large-Scale 3D Mitochondria Instance Segmentation from EM Images","type":"publication"},{"authors":["Aarush Gupta*","Dakshit Agrawal*","Hardik Chauhan","Jose Dolz","Marco Pedersoli"],"categories":null,"content":"","date":1533148200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1533148200,"objectID":"f1c5271a1e16e76d155dd825f34e07b5","permalink":"https://aarushgupta.github.io/publication/att/","publishdate":"2018-08-02T00:00:00+05:30","relpermalink":"/publication/att/","section":"publication","summary":"In this paper we propose a new approach for classifying the global emotion of images containing groups of people. To achieve this task, we consider two different and complementary sources of information: i) a global representation of the entire image (ii) a local representation where only faces are considered. While the global representation of the image is learned with a convolutional neural network (CNN), the local representation is obtained by merging face features through an attention mechanism. The two representations are first learned independently with two separate CNN branches and then fused through concatenation in order to obtain the final group-emotion classifier. For our submission to the EmotiW 2018 group-level emotion recognition challenge, we combine several variations of the proposed model into an ensemble, obtaining a final accuracy of 64.83% on the test set and ranking 4th among all challenge participants.","tags":[],"title":"An Attention Model for Group Level Emotion Recognition","type":"publication"}]